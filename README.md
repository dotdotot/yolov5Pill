# Pill Project
ğŸ—“ í”„ë¡œì íŠ¸ ì†Œê°œ : Pill Project</br>
ğŸ—“ ê¸°ê°„ : 2022.9.24 ~   </br>
ğŸ—“ íŒ€ì›:  [ì¤€ì„](https://github.com/dotdotot)</br>
ğŸ—“ ë¦¬ë·°ì–´: [ì¤€ì„](https://github.com/dotdotot)</br></br>

# Yolov5
yolo ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í•™ìŠµì‹œí‚¤ê¸°(colab)</br>

1. ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸</br>
<code>
    #ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸</br>

    from google.colab import drive

    drive.mount('/content/drive')
</code>

2. í™˜ê²½ ì„¸íŒ…</br>
<code>
    ë‚´ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¡œ ì´ë™

    %cd "/content/drive/MyDrive"

    Yolov5 github ë ˆí¬ì§€í† ë¦¬ clone

    !git clone https://github.com/ultralytics/yolov5.git

    í•„ìš”í•œ ëª¨ë“ˆ ì„¤ì¹˜
    !pip install -U -r yolov5/requirements.txt
</code>
<code>
    import torch

    #íŒŒì´í† ì¹˜ ë²„ì „ í™•ì¸, cuda device properties í™•ì¸

    print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
<code>

ëŸ°íƒ€ì„ -> ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ì— ë“¤ì–´ê°€ì„œ í•˜ë“œì›¨ì–´ ê°€ì†ê¸° GPUë¡œ ë³€ê²½</br>
ì´í›„ custom ëª¨ë¸ì— ì‚¬ìš©í•  ë°ì´í„° ìˆ˜ì§‘í•˜ê¸°</br>

3. data.yaml íŒŒì¼ ìƒì„±</br>
data.yaml : ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ì‘ì€ íŠœí† ë¦¬ì–¼ ê°™ì€ ê²ƒ (ë‚´ ë“œë¼ì´ë¸Œ/dataset ì•„ë˜ì— ë§Œë“¤ì–´ì¤€ë‹¤)  

![ë‹¤ìš´ë¡œë“œ](https://user-images.githubusercontent.com/77331459/194784144-00d6d2a6-9074-4eed-9f9b-6cca9decdd79.png)  

íŒŒì¼ì˜ ë‚´ìš©ì€ ê·¸ë¦¼ê³¼ ê°™ì´ ì ì–´ì£¼ë©´ ëœë‹¤.  

classê°€ ì—¬ëŸ¬ê°œë¼ë©´ ncì˜ ê°œìˆ˜ë¥¼ classì˜ ê°œìˆ˜ë§Œí¼ ì§€ì •í•˜ê³  names ë°°ì—´ ë‚´ë¶€ì— class ì´ë¦„ì„ ì ì–´ì£¼ë©´ ëœë‹¤.  

ì¦‰, ncëŠ” ìì‹ ì´ í•™ìŠµì‹œí‚¤ê³ ì í•˜ëŠ” í´ë˜ìŠ¤ì˜ ìˆ˜(number)ê³   

namesì—ëŠ” ê·¸ í´ë˜ìŠ¤ì˜  ì´ë¦„ì„ ë°°ì—´ë¡œ ì ì–´ì£¼ë©´ ë¨  

ì—¬ëŸ¬ê°œì¼ ê²½ìš° ['class1','class2'] ì²˜ëŸ¼..    



4.  labels/images í´ë” ì •ë¦¬í•´ì£¼ê¸°  

2ë²ˆì—ì„œ ë§Œë“¤ì–´ë†¨ë˜ ë‚´ ë°ì´í„°ì…‹ë“¤ì„ ëª¨ë‘ ì •ë¦¬í•´ì¤˜ì•¼í•œë‹¤.  

images/train ì—ëŠ” í›ˆë ¨ì‹œí‚¤ê³ ì í•˜ëŠ” imageë“¤ì„ ë„£ê³   

images/val ì—ëŠ” validationì— ì‚¬ìš©ë˜ëŠ” imageë“¤,   

labels/train  í›ˆë ¨ì‹œí‚¤ëŠ” imageì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ê°€ ì €ì¥ëœ txtíŒŒì¼ë“¤  

labels/val ì—ëŠ”  validationì— ì‚¬ìš©ë˜ëŠ”  imageì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ txtíŒŒì¼ë“¤ ì„ ëª¨ë‘ ì—…ë¡œë“œ í•´ì¤€ë‹¤.  


5. ëª¨ë¸ ì„ íƒí•˜ê¸°  

![ë‹¤ìš´ë¡œë“œ (1)](https://user-images.githubusercontent.com/77331459/194784149-35ee09f9-91a9-42a0-917b-6b39c85f147d.png)   


yolov5/models ì— ì—¬ëŸ¬ íŒŒì¼ë“¤ì´ ìˆë‹¤. ê·¸ ì¤‘ í•˜ë‚˜ ì„ íƒí•˜ì—¬ í•´ë‹¹ íŒŒì¼ ë‚´ìš©ì¤‘ nc ë¥¼ ìì‹ ì´ í•™ìŠµì‹œí‚¤ê³ ì í•˜ëŠ” í´ë˜ìŠ¤ ê°œìˆ˜ë¡œ ë°”ê¾¼ë‹¤.  

![ë‹¤ìš´ë¡œë“œ (2)](https://user-images.githubusercontent.com/77331459/194784150-8db0c7dc-515d-4467-8408-dd77a975670a.png)    



6. training ì‹œí‚¤ê¸° !!  

training ì‹œí‚¤ê¸° ì „ì— í•­ìƒ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì¤€ë‹¤  

<code>
    !pip install -U PyYAML
</code>  

ì½”ë“œë¥¼ í†µí•´ yolov5 ë””ë ‰í† ë¦¬ë¡œ ì´ë™  

<code>
    %cd /content/drive/My\ Drive/yolov5
</code>  

img: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°  

batch: ë°°ì¹˜ í¬ê¸°  

epochs: í•™ìŠµ epoch ìˆ˜ (ì°¸ê³ : 3000ê°œ ì´ìƒì´ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤ê³  í•œë‹¤...)  

data: data.yaml íŒŒì¼ ê²½ë¡œ  

cfg: ëª¨ë¸ êµ¬ì„± ì§€ì •  


weights: ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ì‚¬ìš©ì ì •ì˜ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤(ì°¸ê³ : Ultraalytics Google Drive í´ë”ì—ì„œ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤).  

name: ëª¨ë¸ì´ ì €ì¥ ë  í´ë” ì´ë¦„  

nosave: ìµœì¢… ì²´í¬í¬ì¸íŠ¸ë§Œ ì €ì¥  

cache: ë” ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ìºì‹œ  
  


!python train.py --img 640 --batch 30 --epochs 100 --data /content/drive/My\ Drive/dataset/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name [ë‚´ê°€ ì •í•œ í´ë”ëª…]  

ë¥¼ ì‹¤í–‰í•˜ë©´ í›ˆë ¨ì´ ì‹œì‘ëœë‹¤.  

í›ˆë ¨ì´ ì‹œì‘ë˜ê³  ì™„ë£Œë˜ë©´ ì–´ëŠ í´ë”ì— .ptíŒŒì¼ì´ ìƒì„±ì´ ë˜ì—ˆëŠ”ì§€ í™•ì¸ê°€ëŠ¥í•˜ë‹¤.  
  
  
7. yolov5 ì‹¤í–‰  
cd /content/drive/MyDrive/yolov5 ì½”ë“œë¥¼ ì‹¤í–‰í•´ .ptíŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ìœ„ì¹˜ë¡œ ì´ë™í•œë‹¤  
#ì‚¬ìš©  

!python detect.py --img 640 --weights "/content/yolov5/runs/train/coustomYolov5m/weights/best.pt" --source "/content/drive/MyDrive/testImages"  



# Color  
CNN(Convolutional Neural Networks)  

CNN(Convolutional Neural Networks)ì€ ìˆ˜ë™ìœ¼ë¡œ íŠ¹ì§•ì„ ì¶”ì¶œí•  í•„ìš” ì—†ì´ ë°ì´í„°ë¡œë¶€í„° ì§ì ‘ í•™ìŠµí•˜ëŠ” ë”¥ëŸ¬ë‹ì„ ìœ„í•œ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜  

íŠ¹ì§• ì¶”ì¶œ ì˜ì—­ì€ í•©ì„±ê³±ì¸µ(Convolution layer)ê³¼ í’€ë§ì¸µ(Pooling layer)ì„ ì—¬ëŸ¬ ê²¹ ìŒ“ëŠ” í˜•íƒœ(Conv+Maxpool)ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¶€ë¶„ì€ Fully connected(FC) í•™ìŠµ ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜  

![images_eodud0582_post_00e763c2-8f36-44e9-9303-7a710256d8c9_image](https://user-images.githubusercontent.com/77331459/194784494-53df4a7a-f72a-498b-b6c7-cfe5d74ac9bf.png)
CNN ì•Œê³ ë¦¬ì¦˜ì˜ êµ¬ì¡°  

  
CNNì€ ì£¼ë¡œ ì´ë¯¸ì§€ë‚˜ ì˜ìƒ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ì“°ì´ëŠ”ë°, ì˜ìƒì—ì„œ ê°ì²´, ì–¼êµ´, ì¥ë©´ ì¸ì‹ì„ ìœ„í•œ íŒ¨í„´ì„ ì°¾ì„ ë•Œ íŠ¹íˆ ìœ ìš©í•˜ë©°, ì˜¤ë””ì˜¤, ì‹œê³„ì—´, ì‹ í˜¸ ë°ì´í„°ì™€ ê°™ì´ ì˜ìƒ ì´ì™¸ì˜ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë°ë„ íš¨ê³¼ì   

  
ê³¼ì • :  
1. ë°ì´í„°ì…‹ ì¤€ë¹„  
2. ê²½ë¡œ ì§€ì • ë° ë°ì´í„° ì‚´í´ë³´ê¸°  
3. ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬  
4. ëª¨ë¸ êµ¬ì„±  
5. ëª¨ë¸ í•™ìŠµ  
6. í…ŒìŠ¤íŠ¸ í‰ê°€  
7. ëª¨ë¸ ì €ì¥  
  
1. ë°ì´í„°ì…‹ ì¤€ë¹„  
train, validation, test í´ë”ë¥¼ ìƒì„±  
  
ê²½ë¡œ ì§€ì •  

<code>
    # ê¸°ë³¸ ê²½ë¡œ  
    base_dir = 'C:\\vsCode\PillProject\image\color\\'  
    train_dir = os.path.join(base_dir, 'train')  
    validation_dir = os.path.join(base_dir, 'validation')  
    test_dir = os.path.join(base_dir, 'test')  
      
    # í›ˆë ¨ìš© ì´ë¯¸ì§€ ê²½ë¡œ  
    train_red_dir = os.path.join(train_dir, 'red')  
    train_green_dir = os.path.join(train_dir, 'green')  
    train_blue_dir = os.path.join(train_dir, 'blue')  
    train_orange_dir = os.path.join(train_dir, 'orange')  
    train_white_dir = os.path.join(train_dir, 'white')  
      
    # ê²€ì¦ìš© ì´ë¯¸ì§€ ê²½ë¡œ  
    validation_white_dir = os.path.join(validation_dir, 'white')  
    validation_red_dir = os.path.join(validation_dir, 'red')  
    validation_green_dir = os.path.join(validation_dir, 'green')  
    validation_orange_dir = os.path.join(validation_dir, 'orange')  
    validation_blue_dir = os.path.join(validation_dir, 'blue')  
      
    # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ê²½ë¡œ  
    test_white_dir = os.path.join(test_dir, 'white')  
    test_red_dir = os.path.join(test_dir, 'red')  
    test_green_dir = os.path.join(test_dir, 'green')  
    test_orange_dir = os.path.join(test_dir, 'orange')  
    test_blue_dir = os.path.join(test_dir, 'blue')  

</code>  
  
ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ì¡°íšŒ  
os.listdir()ì„ ì‚¬ìš©í•˜ì—¬ ê²½ë¡œ ë‚´ì— ìˆëŠ” íŒŒì¼ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ì˜ í˜•íƒœë¡œ ë°˜í™˜ë°›ì•„ í™•ì¸í•©ë‹ˆë‹¤.  
  
<code>  
    # í›ˆë ¨ìš© ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ì¡°íšŒ  
    train_white_fnames = os.listdir(train_white_dir)  
    train_red_fnames = os.listdir(train_red_dir)  
    train_green_fnames = os.listdir(train_green_dir)  
    train_orange_fnames = os.listdir(train_orange_dir)  
    train_blue_fnames = os.listdir(train_blue_dir)  
    print(train_white_fnames)  
    print(train_red_fnames)  
    print(train_green_fnames)  
    print(train_orange_fnames)  
    print(train_blue_fnames)  
      
    #ê° ë””ë ‰í† ë¦¬ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ í™•ì¸  
      
    print('Total training red images :', len(os.listdir(train_red_dir)))  
    print('Total training green images :', len(os.listdir(train_green_dir)))  
    print('Total training blue images :', len(os.listdir(train_blue_dir)))  
    print('Total training orange images :', len(os.listdir(train_orange_dir)))  
    print('Total training white images :', len(os.listdir(train_white_dir)))  
      
    print('Total validation white images :', len(os.listdir(validation_white_dir)))  
    print('Total validation red images :', len(os.listdir(validation_red_dir)))  
    print('Total validation green images :', len(os.listdir(validation_green_dir)))  
    print('Total validation orange images :', len(os.listdir(validation_orange_dir)))  
    print('Total validation blue images :', len(os.listdir(validation_blue_dir)))  
      
    print('Total test white images :', len(os.listdir(test_white_dir)))  
    print('Total test red images :', len(os.listdir(test_red_dir)))  
    print('Total test green images :', len(os.listdir(test_green_dir)))  
    print('Total test orange images :', len(os.listdir(test_orange_dir)))  
    print('Total test blue images :', len(os.listdir(test_blue_dir)))  

</code>  

![ì œëª© ì—†ìŒ](https://user-images.githubusercontent.com/77331459/194784686-c3704c6c-f58c-44ba-87ad-71e0fa3f3d9a.png)  
  
  
  
ì´ë¯¸ì§€ í™•ì¸  

<code>
    import matplotlib.pyplot as plt  

    import matplotlib.image as mpimg  
      
    nrows, ncols = 4, 4  
    pic_index = 0  
      
    fig = plt.gcf()  
    fig.set_size_inches(ncols*3, nrows*3)  
      
    pic_index += 8  
      
    next_red_pix = [os.path.join(train_red_dir, fname) for fname in train_red_fnames[pic_index-8:pic_index]]  
    next_green_pix = [os.path.join(train_green_dir, fname) for fname in train_green_fnames[pic_index-8:pic_index]]  
    next_blue_pix = [os.path.join(train_blue_dir, fname) for fname in train_blue_fnames[pic_index-8:pic_index]]  
    next_orange_pix = [os.path.join(train_orange_dir, fname) for fname in train_orange_fnames[pic_index-8:pic_index]]  
    next_white_pix = [os.path.join(train_white_dir, fname) for fname in train_white_fnames[pic_index-8:pic_index]]  
      
    for i, img_path in enumerate(next_red_pix + next_green_pix + next_blue_pix + next_orange_pix + next_white_pix):  
        sp = plt.subplot(nrows, ncols, i + 1)  
        sp.axis('OFF')  
          
        img = mpimg.imread(img_path)  
        plt.imshow(img)  
      
    plt.show()  

</code>  

![ì œëª© ì—†ìŒ1](https://user-images.githubusercontent.com/77331459/194784768-71ddcf50-c429-48e0-99b5-d4625466bf2d.png)  
  

ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬  

ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë‹¤ê³  ìƒê°í–ˆìŠµë‹ˆë‹¤. 

ì ì€ ìˆ˜ì˜ ì´ë¯¸ì§€ì—ì„œ ëª¨ë¸ì´ ìµœëŒ€í•œ ë§ì€ ì •ë³´ë¥¼ ë½‘ì•„ë‚´ì„œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡, augmentationì„ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.  

Augmentationì´ë¼ëŠ” ê²ƒì€, ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•  ë•Œë§ˆë‹¤ ì„ì˜ë¡œ ë³€í˜•ì„ ê°€í•¨ìœ¼ë¡œì¨ ë§ˆì¹˜ í›¨ì”¬ ë” ë§ì€ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ê³µë¶€í•˜ëŠ” ê²ƒê³¼ ê°™ì€ í•™ìŠµ íš¨ê³¼ë¥¼ ë‚´ê²Œ í•´ì¤ë‹ˆë‹¤.  

ê¸°ì¡´ì˜ ë°ì´í„°ì˜ ì •ë³´ëŸ‰ì„ ë³´ì¡´í•œ ìƒíƒœë¡œ ë…¸ì´ì¦ˆë¥¼ ì£¼ëŠ” ë°©ì‹ì¸ë°, ì´ëŠ” ë‹¤ì‹œ ë§í•˜ë©´, ë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” ì •ë³´ëŸ‰ì€ ë³€í•˜ì§€ ì•Šê³  ë‹¨ì§€ ì •ë³´ëŸ‰ì— ì•½ê°„ì˜ ë³€í™”ë¥¼ ì£¼ëŠ” ê²ƒìœ¼ë¡œ, ë”¥ëŸ¬ë‹ìœ¼ë¡œ ë¶„ì„ëœ ë°ì´í„°ì˜ ê°•í•˜ê²Œ í‘œí˜„ë˜ëŠ” ê³ ìœ ì˜ íŠ¹ì§•ì„ ì¡°ê¸ˆ ëŠìŠ¨í•˜ê²Œ ë§Œë“¤ì–´ëŠ” ê²ƒì´ë¼ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.   

Augmentationì„ í†µí•´ ê²°ê³¼ì ìœ¼ë¡œ ê³¼ì í•©(ì˜¤ë²„í”¼íŒ…)ì„ ë§‰ì•„ ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì—ë§Œ ë§ì¶°ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³ , ìƒˆë¡œìš´ ì´ë¯¸ì§€ë„ ì˜ ë¶„ë¥˜í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì˜ˆì¸¡ ë²”ìœ„ë„ ë„“í˜€ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

ì´ëŸ° ì „ì²˜ë¦¬ ê³¼ì •ì„ ë•ê¸° ìœ„í•´ ì¼€ë¼ìŠ¤ëŠ” ImageDataGenerator í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ImageDataGeneratorëŠ” ì•„ë˜ì™€ ê°™ì€ ì¼ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤  

* í•™ìŠµ ê³¼ì •ì—ì„œ ì´ë¯¸ì§€ì— ì„ì˜ ë³€í˜• ë° ì •ê·œí™” ì ìš©  
* ë³€í˜•ëœ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆëŠ” generator ìƒì„±  
- generatorë¥¼ ìƒì„±í•  ë•Œ flow(data, labels), flow_from_directory(directory) ë‘ ê°€ì§€ í•¨ìˆ˜ë¥¼ ì‚¬ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
- fit_generator(fit), evaluate_generator í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ generatorë¡œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì™€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  í‰ê°€ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
  
ì´ë¯¸ì§€ ë°ì´í„° ìƒì„±  

ImageDataGeneratorë¥¼ í†µí•´ì„œ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì¤„ ê²ƒì…ë‹ˆë‹¤.   

ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¦ì‹ì‹œí‚¬ ê²ƒì¸ì§€ ì•„ë˜ì™€ ê°™ì€ ì˜µì…˜ì„ í†µí•´ì„œ ì„¤ì •í•©ë‹ˆë‹¤.    

ì°¸ê³ ë¡œ, augmentationì€ train ë°ì´í„°ì—ë§Œ ì ìš©ì‹œì¼œì•¼ í•˜ê³ , validation ë° test ì´ë¯¸ì§€ëŠ” augmentationì„ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  

ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•  ë•Œì—ëŠ” ì´ë¯¸ì§€ ì›ë³¸ì„ ì‚¬ìš©í•´ì•¼ í•˜ê¸°ì— rescaleë§Œ ì ìš©í•´ ì •ê·œí™”í•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤  

<code>
# ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Image augmentation
    #trainì…‹ì—ë§Œ ì ìš©
    train_datagen = ImageDataGenerator(rescale = 1./255, # ëª¨ë“  ì´ë¯¸ì§€ ì›ì†Œê°’ë“¤ì„ 255ë¡œ ë‚˜ëˆ„ê¸°  
                                    rotation_range=25, # 0~25ë„ ì‚¬ì´ì—ì„œ ì„ì˜ì˜ ê°ë„ë¡œ ì›ë³¸ì´ë¯¸ì§€ë¥¼ íšŒì „  
                                    width_shift_range=0.05, # 0.05ë²”ìœ„ ë‚´ì—ì„œ ì„ì˜ì˜ ê°’ë§Œí¼ ì„ì˜ì˜ ë°©í–¥ìœ¼ë¡œ ì¢Œìš° ì´ë™  
                                    height_shift_range=0.05, # 0.05ë²”ìœ„ ë‚´ì—ì„œ ì„ì˜ì˜ ê°’ë§Œí¼ ì„ì˜ì˜ ë°©í–¥ìœ¼ë¡œ ìƒí•˜ ì´ë™  
                                    zoom_range=0.2, # (1-0.2)~(1+0.2) => 0.8~1.2 ì‚¬ì´ì—ì„œ ì„ì˜ì˜ ìˆ˜ì¹˜ë§Œí¼ í™•ëŒ€/ì¶•ì†Œ  
                                    horizontal_flip=True, # ì¢Œìš°ë¡œ ë’¤ì§‘ê¸°                                     
                                    vertical_flip=True,  
                                    fill_mode='nearest'  
                                    )   
    #validation ë° test ì´ë¯¸ì§€ëŠ” augmentationì„ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤;  
    #ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•  ë•Œì—ëŠ” ì´ë¯¸ì§€ ì›ë³¸ì„ ì‚¬ìš© (rescaleë§Œ ì§„í–‰)  
    validation_datagen = ImageDataGenerator(rescale = 1./255)  
    test_datagen = ImageDataGenerator(rescale = 1./255)   

</code>  

ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ê°€ ì ì–´ì„œ, batch_sizeë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì— ì—¬ëŸ¬ ì‹œí–‰ì°©ì˜¤ì™€ ì–´ë ¤ì›€ì´ ìˆì„ê²ƒì´ë¼ê³  ìƒê°í–ˆìŠµë‹ˆë‹¤.  

Generator ìƒì„±ì‹œ batch_sizeì™€ steps_per_epoch(model fití•  ë•Œ)ë¥¼ ê³±í•œ ê°’ì´ í›ˆë ¨ ìƒ˜í”Œ ìˆ˜ ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.   

ì´ì— ë§ì¶°, flow_from_directory() ì˜µì…˜ì—ì„œ batch_sizeì™€ model fit()/fit_generator() ì˜µì…˜ì˜ steps_per_epoch ê°’ì„ ì¡°ì •í•´ ê°€ë©° í•™ìŠµì„ ì‹œë„í•˜ì˜€ìŠµë‹ˆë‹¤.  

<code>
    #flow_from_directory() ë©”ì„œë“œë¥¼ ì´ìš©í•´ì„œ í›ˆë ¨ê³¼ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ë  ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë§Œë“¤ê¸°
    #ë³€í™˜ëœ ì´ë¯¸ì§€ ë°ì´í„° ìƒì„±
    train_generator = train_datagen.flow_from_directory(train_dir,   
                                                        batch_size=16, # í•œë²ˆì—   ë³€í™˜ëœ ì´ë¯¸ì§€ 16ê°œì”©   ë§Œë“¤ì–´ë¼ ë¼ëŠ” ê²ƒ  
                                                        color_mode='rgba', # í‘ë°±   ì´ë¯¸ì§€ ì²˜ë¦¬  
                                                        class_mode='categorical',   
                                                        target_size=(150,150)) #   target_sizeì— ë§ì¶°ì„œ   ì´ë¯¸ì§€ì˜ í¬ê¸°ê°€ ì¡°ì ˆëœë‹¤  
    validation_generator = validation_datagen.flow_from_directory(validation_dir,   
                                                                batch_size=4,   
                                                                color_mode='rgba',  
                                                                class_mode='categorical',   
                                                                target_size=(150,  150))  
    test_generator = test_datagen.flow_from_directory(test_dir,  
                                                    batch_size=4,  
                                                    color_mode='rgba',  
                                                    class_mode='categorical',  
                                                    target_size=(150,150))  
    #ì°¸ê³ ë¡œ, generator ìƒì„±ì‹œ batch_size x steps_per_epoch (model fitì—ì„œ) <= í›ˆë ¨ ìƒ˜í”Œ ìˆ˜ ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•œë‹¤.  

</code>  
  
<code>
    # class í™•ì¸  
    train_generator.class_indices  
</code>
  
ëª¨ë¸ êµ¬ì„±  

í•©ì„±ê³± ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.  

![image](https://user-images.githubusercontent.com/77331459/194784951-18705042-9f54-43c5-9982-4844afe8e629.png)  
  
ëª¨ë¸ í•™ìŠµ  

ëª¨ë¸ ì»´íŒŒì¼ ë‹¨ê³„ì—ì„œëŠ” compile() ë©”ì„œë“œë¥¼ ì´ìš©í•´ì„œ ì†ì‹¤ í•¨ìˆ˜(loss function)ì™€ ì˜µí‹°ë§ˆì´ì €(optimizer)ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.  

* ì†ì‹¤ í•¨ìˆ˜ë¡œ â€˜binary_crossentropyâ€™ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.(ë³€ê²½ ì˜ˆì •)
* ë˜í•œ, ì˜µí‹°ë§ˆì´ì €ë¡œëŠ” RMSpropì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. RMSprop(Root Mean Square Propagation) ì•Œê³ ë¦¬ì¦˜ì€ í›ˆë ¨ ê³¼ì • ì¤‘ì— í•™ìŠµë¥ ì„ ì ì ˆí•˜ê²Œ ë³€í™”ì‹œì¼œ ì¤ë‹ˆë‹¤.  
* í›ˆë ¨ê³¼ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ì¸ train_generator, validation_generatorë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
* epochsëŠ” ë°ì´í„°ì…‹ì„ í•œ ë²ˆ í›ˆë ¨í•˜ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
* steps_per_epochëŠ” í•œ ë²ˆì˜ ì—í¬í¬ (epoch)ì—ì„œ í›ˆë ¨ì— ì‚¬ìš©í•  ë°°ì¹˜ (batch)ì˜ ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
* validation_stepsëŠ” í•œ ë²ˆì˜ ì—í¬í¬ê°€ ëë‚  ë•Œ, í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ë˜ëŠ” ë°°ì¹˜ (batch)ì˜ ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.

<code>  
    from tensorflow.keras.optimizers import RMSprop  
  
    #compile() ë©”ì„œë“œë¥¼ ì´ìš©í•´ì„œ ì†ì‹¤ í•¨ìˆ˜ (loss function)ì™€ ì˜µí‹°ë§ˆì´ì € (optimizer)ë¥¼ ì§€ì •  
    model.compile(optimizer=RMSprop(learning_rate=0.001), # ì˜µí‹°ë§ˆì´ì €ë¡œëŠ” RMSprop ì‚¬ìš©  
                loss='binary_crossentropy', # ì†ì‹¤ í•¨ìˆ˜ë¡œ â€˜sparse_categorical_crossentropyâ€™ ì‚¬ìš©  
                metrics= ['accuracy'])  
    # RMSprop (Root Mean Square Propagation) Algorithm: í›ˆë ¨ ê³¼ì • ì¤‘ì— í•™ìŠµë¥ ì„ ì ì ˆí•˜ê²Œ ë³€í™”ì‹œí‚¨ë‹¤.  
  
  
  
    #ëª¨ë¸ í›ˆë ¨  
    history = model.fit_generator(train_generator, # train_generatorì•ˆì— Xê°’, yê°’ ë‹¤ ìˆìœ¼ë‹ˆ generatorë§Œ ì£¼ë©´ ëœë‹¤  
                                validation_data=validation_generator, # validatino_generatorì•ˆì—ë„ ê²€ì¦ìš© X,yë°ì´í„°ë“¤ì´ ë‹¤ ìˆìœ¼ë‹ˆ generatorë¡œ ì£¼ë©´ ë¨  
                                steps_per_epoch=4, # í•œ ë²ˆì˜ ì—í¬í¬(epoch)ì—ì„œ í›ˆë ¨ì— ì‚¬ìš©í•  ë°°ì¹˜(batch)ì˜ ê°œìˆ˜ ì§€ì •; generatorë¥¼ 4ë²ˆ ë¶€ë¥´ê² ë‹¤  
                                epochs=100, # ë°ì´í„°ì…‹ì„ í•œ ë²ˆ í›ˆë ¨í•˜ëŠ” ê³¼ì •; epochì€ 100 ì´ìƒì€ ì¤˜ì•¼í•œë‹¤  
                                validation_steps=4, # í•œ ë²ˆì˜ ì—í¬í¬ê°€ ëë‚  ë•Œ, ê²€ì¦ì— ì‚¬ìš©ë˜ëŠ” ë°°ì¹˜(batch)ì˜ ê°œìˆ˜ë¥¼ ì§€ì •; validation_generatorë¥¼ 4ë²ˆ ë¶ˆëŸ¬ì„œ ë‚˜ì˜¨ ì´ë¯¸ì§€ë“¤ë¡œ ì‘ì—…ì„ í•´ë¼  
                                verbose=2)  
    #ì°¸ê³ : validation_stepsëŠ” ë³´í†µ ë‚´ê°€ ì›í•˜ëŠ” ì´ë¯¸ì§€ ìˆ˜ì— flowí•  ë•Œ ì§€ì •í•œ batchsizeë¡œ ë‚˜ëˆˆ ê°’ì„ validation_stepsë¡œ ì§€ì •  

</code>
  
  
ê²°ê³¼ í™•ì¸ ë° í‰ê°€  
í•™ìŠµëœ ëª¨ë¸ ê²°ê³¼ì™€ ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.  

<code>

    # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€  
    model.evaluate(train_generator)  
</code>  

<code>

    model.evaluate(validation_generator)        
</code>  
  
    
ì •í™•ë„ ë° ì†ì‹¤ ì‹œê°í™”  

í›ˆë ¨ ê³¼ì •ì—ì„œ epochì— ë”°ë¥¸ ì •í™•ë„ì™€ ì†ì‹¤ì„ ì‹œê°í™”í™”ì—¬ í™•ì¸í•©ë‹ˆë‹¤.  

<code>

    # ì •í™•ë„ ë° ì†ì‹¤ ì‹œê°í™”  
    acc = history.history['accuracy']  
    val_acc = history.history['val_accuracy']  
    loss = history.history['loss']  
    val_loss = history.history['val_loss']  
      
    epochs = range(len(acc))  
      
    plt.plot(epochs, acc, 'bo', label='Training accuracy')  
    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')  
    plt.title('Training and validation accuracy')  
    plt.legend()  
      
    plt.figure()  
      
    plt.plot(epochs, loss, 'go', label='Training loss')  
    plt.plot(epochs, val_loss, 'g', label='Validation loss')  
    plt.title('Training and validation loss')  
    plt.legend()  
      
    plt.show()  
    
</code>

![image (1)](https://user-images.githubusercontent.com/77331459/194785124-827a1941-125f-4912-b36a-17be341d4d54.png)  
  
í…ŒìŠ¤íŠ¸ í‰ê°€  
#

- datagenImage1 

- epoch 50 , patience=5
batchsize 4
iterations 5

í…ŒìŠ¤íŠ¸ìš©
<code>

    ImageDataGenerator(
        rotation_range = 20,
        width_shift_range = 0.2,
        height_shift_range = 0.2)
    testImage folder = vsCode\\PillProject\\imageT\\color\\test
    target_size = 256,256
    batchsize = 4
    class_mode = categorical
</code>

í›ˆë ¨ìš©(ì„¤ì •ì€ ìœ„ì™€ ë™ì¼)</br>
trainImage folder = vsCode\\PillProject\\imageT\\color\\train</br>

batch_size = 64</br>
num_classes = 5</br>
epochs = 50</br>


<img width="373" alt="datagenImage1í•™ìŠµì´ë¯¸ì§€(patience=5)" src="https://user-images.githubusercontent.com/77331459/205564571-cd6c7f15-97ae-4b2a-bdf4-6480d578ab82.png">

ì‹ ê²½ë§ êµ¬ì„±

<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),

        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )<
</code>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=5)
    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        callbacks=[early_stopping]
    )
</code>

18ì—ì„œ í•™ìŠµì¤‘ì§€ (ìµœëŒ€ 50)</br>
Loss : 0.7770828008651733, Acc : 0.8653846383094788</br>

<img width="251" alt="datagenImage1ê²°ê³¼(patience=5)" src="https://user-images.githubusercontent.com/77331459/205564584-c17a2b86-9722-4c62-953a-81a6a01105e8.png">

<img width="454" alt="datagenImage1ê²€ì¦(patience=5)" src="https://user-images.githubusercontent.com/77331459/205564559-34f99053-f66f-443a-a9f5-1c9966a490b2.png">

#

- datagenImage1 

- epoch 50 , patience = 10
batchsize 4
iterations 5

í…ŒìŠ¤íŠ¸ìš©
<code>

    ImageDataGenerator(
        rotation_range = 20,
        width_shift_range = 0.2,
        height_shift_range = 0.2)
    testImage folder = vsCode\\PillProject\\imageT\\color\\test
    target_size = 256,256
    batchsize = 4
    class_mode = categorical
</code>

í›ˆë ¨ìš©(ì„¤ì •ì€ ìœ„ì™€ ë™ì¼)</br>
trainImage folder = vsCode\\PillProject\\imageT\\color\\train</br>

batch_size = 64</br>
num_classes = 5</br>
epochs = 50</br>

<img width="370" alt="datagenImage1í•™ìŠµì´ë¯¸ì§€(patience=10)" src="https://user-images.githubusercontent.com/77331459/205564671-0d98e75f-9e3c-4e3b-b054-6f1b21ad5345.png">

ì‹ ê²½ë§ êµ¬ì„±

<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),

        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )<
</code>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=5)
    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        callbacks=[early_stopping]
    )
</code>

30ì—ì„œ í•™ìŠµì¤‘ì§€ (ìµœëŒ€ 50)</br>
Loss : 2.2101550102233887, Acc : 0.699999988079071</br>

<img width="248" alt="datagenImage1ê²°ê³¼(patience=10)" src="https://user-images.githubusercontent.com/77331459/205564680-ce4f6eaa-4a2a-4025-b0af-ccfc39b8e297.png">

<img width="465" alt="datagenImage1ê²€ì¦(patience=10)" src="https://user-images.githubusercontent.com/77331459/205564686-247119cc-75ac-4ded-a589-ed70fddf95f7.png">

#

- datagenImage1 

- epoch 50 , patience = 20</br>
batchsize 4 </br>
iterations 5 </br>

í…ŒìŠ¤íŠ¸ìš©
<code>

    ImageDataGenerator(
        rotation_range = 20,
        width_shift_range = 0.2,
        height_shift_range = 0.2)
    testImage folder = vsCode\\PillProject\\imageT\\color\\test
    target_size = 256,256
    batchsize = 4
    class_mode = categorical
</code>

í›ˆë ¨ìš©(ì„¤ì •ì€ ìœ„ì™€ ë™ì¼)</br>
trainImage folder = vsCode\\PillProject\\imageT\\color\\train</br>

batch_size = 64</br>
num_classes = 5</br>
epochs = 50</br>

<img width="374" alt="datagenImage1í•™ìŠµì´ë¯¸ì§€(patience=20)" src="https://user-images.githubusercontent.com/77331459/205564637-c238ab2e-3059-48a1-8157-f7089819c56d.png">

ì‹ ê²½ë§ êµ¬ì„±

<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),

        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )<
</code>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=20)
    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        callbacks=[early_stopping]
    )
</code>

50ê¹Œì§€ í•™ìŠµ ì™„ë£Œ (ìµœëŒ€ 50)</br>
Loss : 0.7318955659866333, Acc : 1.0</br>

<img width="259" alt="datagenImage1ê²°ê³¼(patience=20)" src="https://user-images.githubusercontent.com/77331459/205564626-ada0b971-d632-4b77-acfe-53f874463ee4.png">

<img width="460" alt="datagenImage1ê²€ì¦(patience=20)" src="https://user-images.githubusercontent.com/77331459/205564646-fbd46928-91fa-4499-a46d-ccf3cc10869c.png">

#

- datagenImage2

- epoch 50 , patience = 10</br>
batchsize 4 </br>

í›ˆë ¨ìš©
<code>

    datagen = ImageDataGenerator(
    featurewise_center = True)

    datagen.flow_from_directory(
    'C:\\vsCode\\PillProject\\imageT\\color\\test', 
    shuffle = True, 
    target_size=(256,256), 
    batch_size=batch_size, 
    class_mode = 'categorical')
</code>

í…ŒìŠ¤íŠ¸ìš©(ê²½ë¡œ ì œì™¸ ìœ„ì™€ ë™ì¼)</br>
C:\\vsCode\\PillProject\\imageT\\color\\train</br>

num_classes = 5</br>
epochs = 50</br>

<img width="369" alt="datagenImage2í•™ìŠµì´ë¯¸ì§€(patience=10)" src="https://user-images.githubusercontent.com/77331459/205564721-7181cb4f-7bc7-4973-b93c-859fb2358b7c.png">

ì‹ ê²½ë§ êµ¬ì„±

<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),

        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )<
</code>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=30)

    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        callbacks=[early_stopping]
    )
</code>

35ê¹Œì§€ í•™ìŠµ ì™„ë£Œ (ìµœëŒ€ 50)</br>
Loss : 0.023338522762060165, Acc : 1.0</br>

<img width="261" alt="datagenImage2ê²°ê³¼(patience=10)" src="https://user-images.githubusercontent.com/77331459/205564730-979169c2-b521-4756-8a78-cd2607ae81f6.png">

<img width="453" alt="datagenImage2ê²€ì¦(patience=10)" src="https://user-images.githubusercontent.com/77331459/205564736-e0b6c974-7fa4-43c3-8844-be7b84df4239.png">

#

- datagenImage2

- epoch 50 , patience = 20</br>
batchsize 4 </br>

í›ˆë ¨ìš©
<code>

    datagen = ImageDataGenerator(
    featurewise_center = True)

    datagen.flow_from_directory(
    'C:\\vsCode\\PillProject\\imageT\\color\\test', 
    shuffle = True, 
    target_size=(256,256), 
    batch_size=batch_size, 
    class_mode = 'categorical')
</code>

í…ŒìŠ¤íŠ¸ìš©(ê²½ë¡œ ì œì™¸ ìœ„ì™€ ë™ì¼)</br>
C:\\vsCode\\PillProject\\imageT\\color\\train</br>

num_classes = 5</br>
epochs = 50</br>

<img width="367" alt="datagenImage2í•™ìŠµì´ë¯¸ì§€(patience = 20)" src="https://user-images.githubusercontent.com/77331459/205564745-cd704b5f-ca7a-49de-a24c-020d6dc42212.png">

ì‹ ê²½ë§ êµ¬ì„±

<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),

        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )<
</code>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=30)

    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        callbacks=[early_stopping]
    )
</code>

35ê¹Œì§€ í•™ìŠµ ì™„ë£Œ (ìµœëŒ€ 50)</br>
Loss : 0.38273733854293823, Acc : 0.921875</br>

<img width="270" alt="datagenImage2ê²°ê³¼(patience=20)" src="https://user-images.githubusercontent.com/77331459/205564753-0a10c105-c897-466a-9205-afb2cf4d8f00.png">

<img width="441" alt="datagenImage2ê²€ì¦(patience=20)" src="https://user-images.githubusercontent.com/77331459/205564767-ff55c2d3-d4a8-40ea-bdc1-892d98150114.png">


#

- datagenImage2

- epoch 50 , patience = 30</br>
batchsize 4 </br>

í›ˆë ¨ìš©
<code>

    datagen = ImageDataGenerator(
    featurewise_center = True)

    datagen.flow_from_directory(
    'C:\\vsCode\\PillProject\\imageT\\color\\test', 
    shuffle = True, 
    target_size=(256,256), 
    batch_size=batch_size, 
    class_mode = 'categorical')
</code>

í…ŒìŠ¤íŠ¸ìš©(ê²½ë¡œ ì œì™¸ ìœ„ì™€ ë™ì¼)</br>
C:\\vsCode\\PillProject\\imageT\\color\\train</br>

num_classes = 5</br>
epochs = 50</br>

<img width="370" alt="datagenImage2í•™ìŠµì´ë¯¸ì§€(patience = 30)" src="https://user-images.githubusercontent.com/77331459/205564801-139e2d6a-954c-4bb2-89bd-6bc7a8867203.png">

ì‹ ê²½ë§ êµ¬ì„±

<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),

        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )<
</code>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=30)

    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        callbacks=[early_stopping]
    )
</code>

50ê¹Œì§€ í•™ìŠµ ì™„ë£Œ (ìµœëŒ€ 50)</br>
Loss : 0.10279396176338196, Acc : 0.953125</br>

<img width="267" alt="datagenImage2ê²°ê³¼(patience=30)" src="https://user-images.githubusercontent.com/77331459/205564843-c8d2d900-d0bf-4a5a-a9f3-a753319f9584.png">

<img width="468" alt="datagenImage2ê²€ì¦(patience=30)" src="https://user-images.githubusercontent.com/77331459/205564865-b575dfc7-3d21-4941-8d24-88d37f21bdca.png">


# Shape  
colorì™€ ë™ì¼í•œ cnnëª¨ë¸ì„ ì‚¬ìš©í•˜ì˜€ìŒ

í…ŒìŠ¤íŠ¸ í‰ê°€
#

epoch 5000  |  patience 100</br>

batch_size = 4</br>
#ìƒì„±ì‹œì— íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ë©´ ì–´ë–»ê²Œ augmentationë¥¼ ì§„í–‰í• ì§€ ì§€ì •í•  ìˆ˜ ìˆë‹¤.</br>
<code>

    datagen = ImageDataGenerator(
        featurewise_center = True)
</code>

í…ŒìŠ¤íŠ¸ìš©</br>

<code>

    #ê²½ë¡œ, ì…”í”Œ, ì´ë¯¸ì§€ì‚¬ì´ì¦ˆ, í•œë²ˆì— ì½ì–´ì˜¬ ì´ë¯¸ì§€ ìˆ˜, í´ë˜ìŠ¤ ëª¨ë“œ
    generator = datagen.flow_from_directory(
        'C:\\vsCode\\PillProject\\imageT\\shape\\test', 
        shuffle = True, 
        target_size=(256,256), 
        batch_size=batch_size, 
        class_mode = 'categorical',
        color_mode='grayscale')
    í›ˆë ¨ìš©(ê²½ë¡œë§Œ ë‹¤ë¦„)
    C:\\vsCode\\PillProject\\imageT\\shape\\train

    class_names = ['circle', 'hexagon', 'pentagon', 'rectangle', 'rectangular', 'triangle']
</code>

<img width="366" alt="shapeDatagenImage1í•™ìŠµì´ë¯¸ì§€(patience = 100)" src="https://user-images.githubusercontent.com/77331459/205568304-b21fb1b0-7542-44fe-ad87-db7da1fb1fd9.png">

#ë°°ì¹˜ ì‚¬ì´ì¦ˆì˜ ìˆ˜ë§Œí¼ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•˜ê²Œëœë‹¤.</br>
#ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¦ê°€ì‹œí‚¤ë©´ í•„ìš”í•œ ë©”ëª¨ë¦¬ê°€ ì¦ê°€í•˜ë‚˜ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ”ë° ì‹œê°„ì´ ì ê²Œ ë“ ë‹¤.</br>
#ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ê°ì†Œì‹œí‚¤ë©´ í•„ìš”í•œ ë©”ëª¨ë¦¬ê°€ ê°ì†Œí•˜ë‚˜ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ”ë° ì‹œê°„ì´ ë§ì´ ë“ ë‹¤.</br>
batch_size = 64</br>
#ë¶„ë¥˜ë  í´ë˜ìŠ¤ ê°œìˆ˜</br>
num_classes = 6</br>
#ëª‡ë²ˆ í•™ìŠµì„ ë°˜ë³µí•  ê²ƒì¸ì§€ ê²°ì •</br>
#ì—í¬í¬ê°€ ë§ë‹¤ë©´ ê³¼ì í•© ë¬¸ì œ ë°œìƒê°€ëŠ¥, ì ë‹¤ë©´ ë¶„ë¥˜ë¥¼ ì œëŒ€ë¡œ ëª»í•  ìˆ˜ ìˆë‹¤.</br>
epochs = 5000</br>

#ëª¨ë¸ êµ¬ì„±
<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

#ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ì „ í™˜ê²½ ì„¤ì • (ì •ê·œí™”ê¸°, ì†ì‹¤í•¨ìˆ˜, í‰ê°€ì§€í‘œ)</br>

#ì •ê·œí™”ê¸° - í›ˆë ¨ê³¼ì •ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì¦‰, ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì„¤ì •ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.</br>
#adam, sgd, rmsprop, adagrad ë“±ì´ ìˆìŠµë‹ˆë‹¤.</br>
#ë¶„ë¥˜ì—ëŠ”  â€˜SGDâ€™, â€˜Adamâ€™, â€˜RMSpropâ€™</br>

#ì†ì‹¤í•¨ìˆ˜ - ëª¨ë¸ì´ ìµœì í™”ì— ì‚¬ìš©ë˜ëŠ” ëª©ì  í•¨ìˆ˜ì…ë‹ˆë‹¤.</br>
#mse, categorical_crossentropy, binary_crossentropy ë“±ì´ ìˆìŠµë‹ˆë‹¤.</br>

#í‰ê°€ì§€í‘œ - í›ˆë ¨ì„ ëª¨ë‹ˆí„°ë§ í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.</br>
#ë¶„ë¥˜ì—ì„œëŠ” accuracy, íšŒê·€ì—ì„œëŠ” mse, rmse, r2, mae, mspe, mape, msle ë“±ì´ ìˆìŠµë‹ˆë‹¤.</br>
#ì‚¬ìš©ìê°€ ë©”íŠ¸ë¦­ì„ ì •ì˜í•´ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</br>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )
</code>

#ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ì„œ ì„¤ì •</br>
#Early Stopping ì´ë€ ë„ˆë¬´ ë§ì€ Epoch ì€ overfitting ì„ ì¼ìœ¼í‚¨ë‹¤.Â í•˜ì§€ë§Œ ë„ˆë¬´ ì ì€ Epoch ì€ underfitting ì„ ì¼ìœ¼í‚¨ë‹¤.Â </br>
#ë¼ëŠ” ë”œë ˆë§ˆë¥¼ í•´ê²°í•˜ê¸°ìœ„í•¨</br>

#Epoch ì„ ì •í•˜ëŠ”ë° ë§ì´ ì‚¬ìš©ë˜ëŠ” Early stopping ì€ ë¬´ì¡°ê±´ Epoch ì„ ë§ì´ ëŒë¦° í›„, íŠ¹ì • ì‹œì ì—ì„œ ë©ˆì¶”ëŠ” ê²ƒì´ë‹¤.Â </br>
#ê·¸ íŠ¹ì •ì‹œì ì„ ì–´ë–»ê²Œ ì •í•˜ëŠëƒê°€ Early stopping ì˜ í•µì‹¬ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. </br>
#ì¼ë°˜ì ìœ¼ë¡œ hold-out validation set ì—ì„œì˜ ì„±ëŠ¥ì´ ë”ì´ìƒ ì¦ê°€í•˜ì§€ ì•Šì„ ë•ŒÂ í•™ìŠµì„ ì¤‘ì§€</br>
#https://3months.tistory.com/424 ì°¸ê³ </br>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=100)
    #ModelCheckpoint instanceë¥¼ callbacks íŒŒë¼ë¯¸í„°ì— ë„£ì–´ì¤Œìœ¼ë¡œì¨, ê°€ì¥ validation performance ê°€ ì¢‹ì•˜ë˜ ëª¨ë¸ì„ ì €ì¥í•  ìˆ˜ ìˆê²Œëœë‹¤.
    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)

    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        # ì½œë°±ì„ ì ìš©í•˜ë©´ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ìŒ.
        # ë‹¤ë§Œ, ì ìš©ì‹œí‚¤ë©´ í›ˆë ¨ì„ 12~20ë²ˆ ì‚¬ì´ë¡œ í•˜ê³  ê·¸ëƒ¥ ì—í¬í¬ ìƒê´€ì—†ì´ í›ˆë ¨ì„ ì¤‘ì§€í•¨.
        callbacks=[early_stopping,mc]
    )
</code>

119 ê¹Œì§€ë§Œ í•™ìŠµ (ìµœëŒ€ 5000)</br>
Loss : 4.203685283660889, Acc : 0.5714285969734192</br>

<img width="267" alt="shapeDatagenImage1ê²°ê³¼(patience = 100)" src="https://user-images.githubusercontent.com/77331459/205568319-e5876d66-b066-4396-a993-10d3c7638135.png">

<img width="476" alt="shapeDatagenImage1ê²€ì¦(patience = 100)" src="https://user-images.githubusercontent.com/77331459/205568331-fe73dc87-0817-44b4-bd22-46755b7d734c.png">

#

epoch 5000  |  patience 50</br>

batch_size = 4</br>
#ìƒì„±ì‹œì— íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ë©´ ì–´ë–»ê²Œ augmentationë¥¼ ì§„í–‰í• ì§€ ì§€ì •í•  ìˆ˜ ìˆë‹¤.</br>
<code>

    datagen = ImageDataGenerator(
        featurewise_center = True)
</code>

í…ŒìŠ¤íŠ¸ìš©</br>

<code>

    #ê²½ë¡œ, ì…”í”Œ, ì´ë¯¸ì§€ì‚¬ì´ì¦ˆ, í•œë²ˆì— ì½ì–´ì˜¬ ì´ë¯¸ì§€ ìˆ˜, í´ë˜ìŠ¤ ëª¨ë“œ
    generator = datagen.flow_from_directory(
        'C:\\vsCode\\PillProject\\imageT\\shape\\test', 
        shuffle = True, 
        target_size=(256,256), 
        batch_size=batch_size, 
        class_mode = 'categorical',
        color_mode='grayscale')
    í›ˆë ¨ìš©(ê²½ë¡œë§Œ ë‹¤ë¦„)
    C:\\vsCode\\PillProject\\imageT\\shape\\train

    class_names = ['circle', 'hexagon', 'pentagon', 'rectangle', 'rectangular', 'triangle']
</code>

<img width="379" alt="shapeDatagenImage1í•™ìŠµì´ë¯¸ì§€(patience = 50)" src="https://user-images.githubusercontent.com/77331459/205567847-482f8737-d5fa-4b1c-ab45-1ce391dc1b9e.png">

#ë°°ì¹˜ ì‚¬ì´ì¦ˆì˜ ìˆ˜ë§Œí¼ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•˜ê²Œëœë‹¤.</br>
#ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¦ê°€ì‹œí‚¤ë©´ í•„ìš”í•œ ë©”ëª¨ë¦¬ê°€ ì¦ê°€í•˜ë‚˜ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ”ë° ì‹œê°„ì´ ì ê²Œ ë“ ë‹¤.</br>
#ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ê°ì†Œì‹œí‚¤ë©´ í•„ìš”í•œ ë©”ëª¨ë¦¬ê°€ ê°ì†Œí•˜ë‚˜ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ”ë° ì‹œê°„ì´ ë§ì´ ë“ ë‹¤.</br>
batch_size = 64</br>
#ë¶„ë¥˜ë  í´ë˜ìŠ¤ ê°œìˆ˜</br>
num_classes = 6</br>
#ëª‡ë²ˆ í•™ìŠµì„ ë°˜ë³µí•  ê²ƒì¸ì§€ ê²°ì •</br>
#ì—í¬í¬ê°€ ë§ë‹¤ë©´ ê³¼ì í•© ë¬¸ì œ ë°œìƒê°€ëŠ¥, ì ë‹¤ë©´ ë¶„ë¥˜ë¥¼ ì œëŒ€ë¡œ ëª»í•  ìˆ˜ ìˆë‹¤.</br>
epochs = 5000</br>

#ëª¨ë¸ êµ¬ì„±
<code>

    model = keras.Sequential([
        Conv2D(32, kernel_size = (3,3), padding = 'same', input_shape = train_images.shape[1:],
            activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Conv2D(64, kernel_size = (3,3), padding = 'same', activation=tf.nn.relu),
        MaxPooling2D(pool_size=(2,2)),
        Dropout(0.25),
        
        Flatten(),
        Dense(64, activation=tf.nn.relu),
        Dropout(0.25),
        Dense(num_classes, activation=tf.nn.softmax)
    ])
</code>

#ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ì „ í™˜ê²½ ì„¤ì • (ì •ê·œí™”ê¸°, ì†ì‹¤í•¨ìˆ˜, í‰ê°€ì§€í‘œ)</br>

#ì •ê·œí™”ê¸° - í›ˆë ¨ê³¼ì •ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì¦‰, ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì„¤ì •ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.</br>
#adam, sgd, rmsprop, adagrad ë“±ì´ ìˆìŠµë‹ˆë‹¤.</br>
#ë¶„ë¥˜ì—ëŠ”  â€˜SGDâ€™, â€˜Adamâ€™, â€˜RMSpropâ€™</br>

#ì†ì‹¤í•¨ìˆ˜ - ëª¨ë¸ì´ ìµœì í™”ì— ì‚¬ìš©ë˜ëŠ” ëª©ì  í•¨ìˆ˜ì…ë‹ˆë‹¤.</br>
#mse, categorical_crossentropy, binary_crossentropy ë“±ì´ ìˆìŠµë‹ˆë‹¤.</br>

#í‰ê°€ì§€í‘œ - í›ˆë ¨ì„ ëª¨ë‹ˆí„°ë§ í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.</br>
#ë¶„ë¥˜ì—ì„œëŠ” accuracy, íšŒê·€ì—ì„œëŠ” mse, rmse, r2, mae, mspe, mape, msle ë“±ì´ ìˆìŠµë‹ˆë‹¤.</br>
#ì‚¬ìš©ìê°€ ë©”íŠ¸ë¦­ì„ ì •ì˜í•´ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</br>

<code>

    model.compile(
        loss='categorical_crossentropy',
        optimizer = 'adam',
        metrics=['accuracy']
    )
</code>

#ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ì„œ ì„¤ì •</br>
#Early Stopping ì´ë€ ë„ˆë¬´ ë§ì€ Epoch ì€ overfitting ì„ ì¼ìœ¼í‚¨ë‹¤.Â í•˜ì§€ë§Œ ë„ˆë¬´ ì ì€ Epoch ì€ underfitting ì„ ì¼ìœ¼í‚¨ë‹¤.Â </br>
#ë¼ëŠ” ë”œë ˆë§ˆë¥¼ í•´ê²°í•˜ê¸°ìœ„í•¨</br>

#Epoch ì„ ì •í•˜ëŠ”ë° ë§ì´ ì‚¬ìš©ë˜ëŠ” Early stopping ì€ ë¬´ì¡°ê±´ Epoch ì„ ë§ì´ ëŒë¦° í›„, íŠ¹ì • ì‹œì ì—ì„œ ë©ˆì¶”ëŠ” ê²ƒì´ë‹¤.Â </br>
#ê·¸ íŠ¹ì •ì‹œì ì„ ì–´ë–»ê²Œ ì •í•˜ëŠëƒê°€ Early stopping ì˜ í•µì‹¬ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. </br>
#ì¼ë°˜ì ìœ¼ë¡œ hold-out validation set ì—ì„œì˜ ì„±ëŠ¥ì´ ë”ì´ìƒ ì¦ê°€í•˜ì§€ ì•Šì„ ë•ŒÂ í•™ìŠµì„ ì¤‘ì§€</br>
#https://3months.tistory.com/424 ì°¸ê³ </br>

<code>

    early_stopping=EarlyStopping(monitor='val_loss', patience=50)
    #ModelCheckpoint instanceë¥¼ callbacks íŒŒë¼ë¯¸í„°ì— ë„£ì–´ì¤Œìœ¼ë¡œì¨, ê°€ì¥ validation performance ê°€ ì¢‹ì•˜ë˜ ëª¨ë¸ì„ ì €ì¥í•  ìˆ˜ ìˆê²Œëœë‹¤.
    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)

    history = model.fit(
        train_images, train_labels,
        epochs=epochs,
        validation_data=(test_images, test_labels),
        shuffle=True,
        # ì½œë°±ì„ ì ìš©í•˜ë©´ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ”ì§€ëŠ” ì˜ ëª¨ë¥´ê² ìŒ.
        # ë‹¤ë§Œ, ì ìš©ì‹œí‚¤ë©´ í›ˆë ¨ì„ 12~20ë²ˆ ì‚¬ì´ë¡œ í•˜ê³  ê·¸ëƒ¥ ì—í¬í¬ ìƒê´€ì—†ì´ í›ˆë ¨ì„ ì¤‘ì§€í•¨.
        callbacks=[early_stopping,mc]
    )
</code>

119 ê¹Œì§€ë§Œ í•™ìŠµ (ìµœëŒ€ 5000)</br>
Loss : 4.203685283660889, Acc : 0.5714285969734192</br>

<img width="275" alt="shapeDatagenImage1ê²°ê³¼(patience = 50)" src="https://user-images.githubusercontent.com/77331459/205567857-b39c44eb-e9e5-4aeb-8722-e19768207f47.png">

<img width="461" alt="shapeDatagenImage1ê²€ì¦(patience = 50)" src="https://user-images.githubusercontent.com/77331459/205567868-e0f25d31-cce9-4db9-8383-b6472402189b.png">

# String  
![ë‹¤ìš´ë¡œë“œ (3)](https://user-images.githubusercontent.com/77331459/194784410-d8690c98-46e6-429f-8125-36897550d5d6.png)  

OCRì€ Optical Character Recognitionì˜ ì•½ìë¡œ ì‚¬ëŒì´ ì“°ê±°ë‚˜ ê¸°ê³„ë¡œ ì¸ì‡„í•œ ë¬¸ìì˜ ì˜ìƒì„ ì´ë¯¸ì§€ ìŠ¤ìºë„ˆë¡œ íšë“í•˜ì—¬ ê¸°ê³„ê°€ ì½ì„ ìˆ˜ ìˆëŠ” ë¬¸ìë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ ëœ»í•œë‹¤.  

íŒŒì´ì¬ì—ì„œ ì‚¬ìš©í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” pytesseractì´ë‹¤.  

<code>
í…Œì„œë™íŠ¸(Tesseract)ëŠ” ë‹¤ì–‘í•œ ìš´ì˜ ì²´ì œë¥¼ ìœ„í•œ ê´‘í•™ ë¬¸ì ì¸ì‹ ì—”ì§„ì´ë‹¤. ì´ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” Apache License, ë²„ì „ 2.0,ì— ë”°ë¼ ë°°í¬ë˜ëŠ” ë¬´ë£Œ ì†Œí”„íŠ¸ì›¨ì–´ì´ë©° 2006ë…„ë¶€í„° Googleì—ì„œ ê°œë°œì„ í›„ì›í–ˆë‹¤.
</code>  

ê¸°ëŠ¥

* get_languages Tesseract OCRì—ì„œ í˜„ì¬ ì§€ì›í•˜ëŠ” ëª¨ë“  ì–¸ì–´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. 
* get_tesseract_version ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ Tesseract ë²„ì „ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
* image_to_string Tesseract OCR ì²˜ë¦¬ì—ì„œ ìˆ˜ì •ë˜ì§€ ì•Šì€ ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
* image_to_boxes ì¸ì‹ ëœ ë¬¸ìì™€ í•´ë‹¹ ìƒì ê²½ê³„ë¥¼ í¬í•¨í•˜ëŠ” ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
* image_to_data ìƒì ê²½ê³„, ì‹ ë¢°ë„ ë° ê¸°íƒ€ ì •ë³´ê°€ í¬í•¨ ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. Tesseract 3.05 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ Tesseract TSV ë¬¸ì„œ ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.
* image_to_osd ë°©í–¥ ë° ìŠ¤í¬ë¦½íŠ¸ ê°ì§€ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
* image_to_alto_xml Tesseractì˜ ALTO XML í˜•ì‹ì˜ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
* run_and_get_output Tesseract OCRì—ì„œ ì›ì‹œ ì¶œë ¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤. tesseractë¡œ ì „ì†¡ë˜ëŠ” ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì¢€ ë” ì œì–´ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë§¤ê°œ ë³€ìˆ˜

* image ê°ì²´ ë˜ëŠ” ë¬¸ìì—´-Tesseractì—ì„œ ì²˜ë¦¬ í•  ì´ë¯¸ì§€ì˜ PIL ì´ë¯¸ì§€ / NumPy ë°°ì—´ ë˜ëŠ” íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œ ëŒ€ì‹  ê°ì²´ë¥¼ ì „ë‹¬í•˜ë©´ pytesseractëŠ” ì•”ì‹œ ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ RGB ëª¨ë“œ ë¡œ ë³€í™˜ í•©ë‹ˆë‹¤ .
* lang String-Tesseract ì–¸ì–´ ì½”ë“œ ë¬¸ìì—´ì…ë‹ˆë‹¤. ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ì€ engì…ë‹ˆë‹¤ ! ì—¬ëŸ¬ ì–¸ì–´ì˜ ì˜ˆ : lang = 'eng + fra'
* config String- pytesseract í•¨ìˆ˜ë¥¼ í†µí•´ ì‚¬ìš©í•  ìˆ˜ì—†ëŠ” ì¶”ê°€ ì‚¬ìš©ì ì§€ì • êµ¬ì„± í”Œë˜ê·¸ ì…ë‹ˆë‹¤. ì˜ˆ : config = '-psm 6'
* nice Integer-Tesseract ì‹¤í–‰ì— ëŒ€í•œ í”„ë¡œì„¸ì„œ ìš°ì„  ìˆœìœ„ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. Windowsì—ì„œëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. NiceëŠ” ìœ ë‹‰ìŠ¤ì™€ ìœ ì‚¬í•œ í”„ë¡œì„¸ìŠ¤ì˜ ìš°ìˆ˜ì„±ì„ ì¡°ì •í•©ë‹ˆë‹¤.
* output_type í´ë˜ìŠ¤ ì†ì„±-ì¶œë ¥ ìœ í˜•ì„ ì§€ì •í•˜ë©° ê¸°ë³¸ê°’ì€ string ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ëª¨ë“  ìœ í˜•ì˜ ì „ì²´ ëª©ë¡ì€ pytesseract.Output í´ë˜ìŠ¤ ì˜ ì •ì˜ë¥¼ í™•ì¸í•˜ì„¸ìš” .
* timeout Integer ë˜ëŠ” Float-OCR ì²˜ë¦¬ë¥¼ìœ„í•œ ê¸°ê°„ (ì´ˆ). ê·¸ í›„ pytesseractê°€ ì¢…ë£Œë˜ê³  RuntimeErrorê°€ ë°œìƒí•©ë‹ˆë‹¤.
* pandas_config Dict- Output.DATAFRAME ìœ í˜• ì—ë§Œ í•´ë‹¹ë©ë‹ˆë‹¤ . pandas.read_csvì— ëŒ€í•œ ì‚¬ìš©ì ì§€ì • ì¸ìˆ˜ê°€ìˆëŠ” ì‚¬ì „ . image_to_data ì˜ ì¶œë ¥ì„ ì‚¬ìš©ì ì •ì˜ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ .



# ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
* yolov5

colorì—ì„œ ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
* numpy
* cv2
* KMeans
* matplotlib
* PIL
* os

colorCssì—ì„œ ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
* pandas
* numpy
* matplotlib
* seaborn
* tensorflow
* os
* PIL
* shutil

shapeì—ì„œ ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
* pandas
* numpy
* matplotlib
* seaborn
* tensorflow
* os
* PIL
* shutil

stringì—ì„œ ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
* Image
* pytesseract

# Commit ê·œì¹™
> ì»¤ë°‹ ì œëª©ì€ ìµœëŒ€ 50ì ì…ë ¥  

ë³¸ë¬¸ì€ í•œ ì¤„ ìµœëŒ€ 72ì ì…ë ¥  

Commit ë©”ì„¸ì§€  


ğŸª›[chore]: ì½”ë“œ ìˆ˜ì •, ë‚´ë¶€ íŒŒì¼ ìˆ˜ì •.  

âœ¨[feat]: ìƒˆë¡œìš´ ê¸°ëŠ¥ êµ¬í˜„.  

ğŸ¨[style]: ìŠ¤íƒ€ì¼ ê´€ë ¨ ê¸°ëŠ¥.(ì½”ë“œì˜ êµ¬ì¡°/í˜•íƒœ ê°œì„ )  

â•[add]: Feat ì´ì™¸ì˜ ë¶€ìˆ˜ì ì¸ ì½”ë“œ ì¶”ê°€, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€  

ğŸ”§[file]: ìƒˆë¡œìš´ íŒŒì¼ ìƒì„±, ì‚­ì œ ì‹œ  

ğŸ›[fix]: ë²„ê·¸, ì˜¤ë¥˜ í•´ê²°.  

ğŸ”¥[del]: ì“¸ëª¨ì—†ëŠ” ì½”ë“œ/íŒŒì¼ ì‚­ì œ.  

ğŸ“[docs]: READMEë‚˜ WIKI ë“±ì˜ ë¬¸ì„œ ê°œì •.  

ğŸ’„[mod]: storyboard íŒŒì¼,UI ìˆ˜ì •í•œ ê²½ìš°.  

âœï¸[correct]: ì£¼ë¡œ ë¬¸ë²•ì˜ ì˜¤ë¥˜ë‚˜ íƒ€ì…ì˜ ë³€ê²½, ì´ë¦„ ë³€ê²½ ë“±ì— ì‚¬ìš©í•©ë‹ˆë‹¤.  

ğŸšš[move]: í”„ë¡œì íŠ¸ ë‚´ íŒŒì¼ì´ë‚˜ ì½”ë“œ(ë¦¬ì†ŒìŠ¤)ì˜ ì´ë™  

âªï¸[rename]: íŒŒì¼ ì´ë¦„ ë³€ê²½ì´ ìˆì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  

âš¡ï¸[improve]: í–¥ìƒì´ ìˆì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  

â™»ï¸[refactor]: ì „ë©´ ìˆ˜ì •ì´ ìˆì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  

ğŸ”€[merge]: ë‹¤ë¥¸ë¸Œë Œì¹˜ë¥¼ merge í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  

âœ… [test]: í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  
